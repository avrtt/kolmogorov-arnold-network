{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tfkan.layers import Conv2DKAN, DenseKAN\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fashion-mnist dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# normalize data\n",
    "x_train = np.expand_dims(x_train / 255.0, axis=-1).astype(np.float32)\n",
    "x_test = np.expand_dims(x_test / 255.0, axis=-1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To call `update_grid_from_samples()` in user-define training logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2dkan (Conv2DKAN)       (None, 12, 12, 8)         1658      \n",
      "                                                                 \n",
      " layer_normalization (Layer  (None, 12, 12, 8)         16        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2dkan_1 (Conv2DKAN)     (None, 4, 4, 16)          24416     \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 16)                0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense_kan (DenseKAN)        (None, 10)                1290      \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27380 (106.95 KB)\n",
      "Trainable params: 24970 (97.54 KB)\n",
      "Non-trainable params: 2410 (9.41 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# KAN\n",
    "kan = tf.keras.models.Sequential([\n",
    "    Conv2DKAN(filters=8, kernel_size=5, strides=2, padding='valid', kan_kwargs={'grid_size': 3}),\n",
    "    tf.keras.layers.LayerNormalization(),\n",
    "    Conv2DKAN(filters=16, kernel_size=5, strides=2, padding='valid', kan_kwargs={'grid_size': 3}),\n",
    "    GlobalAveragePooling2D(),\n",
    "    DenseKAN(10, grid_size=3),\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "kan.build(input_shape=(None, 28, 28, 1))\n",
    "kan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kan(\n",
    "    model,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_valid=None,\n",
    "    y_valid=None,\n",
    "    epochs: int=5,\n",
    "    learning_rate: float=1e-3,\n",
    "    batch_size: int=128,\n",
    "    verbose: int=1\n",
    "):  \n",
    "    # build optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # build dataset\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_set = train_set.batch(batch_size)\n",
    "    if x_valid is not None and y_valid is not None:\n",
    "        valid_set = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "        valid_set = valid_set.batch(batch_size)\n",
    "    else:\n",
    "        valid_set = None\n",
    "\n",
    "    # define loss function\n",
    "    loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    # define metrics\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "    step = 0\n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        # reset metrics\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "\n",
    "        for x_batch, y_batch in train_set:\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(x_batch, training=True)\n",
    "                loss = loss_func(y_batch, y_pred)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "            # update weights\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            \n",
    "            train_loss(loss)\n",
    "            train_accuracy(y_batch, y_pred)\n",
    "            step += 1\n",
    "\n",
    "            if verbose > 0 and step % verbose == 0:\n",
    "                # clear the output and print the updated metrics\n",
    "                print(f\"[EPCOH: {epoch+1:3d} / {epochs:3d}, STEP: {step:6d}]: \\\n",
    "train_loss: {train_loss.result():.4f}, train_accuracy: {train_accuracy.result():.4f}\", end='\\r')\n",
    "        \n",
    "        # callback after each epoch\n",
    "        # call update_grid_from_samples method\n",
    "        for layer in model.layers:\n",
    "            if hasattr(layer, 'update_grid_from_samples'):\n",
    "                layer.update_grid_from_samples(x_batch)\n",
    "            x_batch = layer(x_batch)\n",
    "\n",
    "        # eval on validation set\n",
    "        if valid_set:\n",
    "            valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "            valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "            for x_batch, y_batch in valid_set:\n",
    "                y_pred = model(x_batch, training=False)\n",
    "                loss = tf.reduce_mean(loss_func(y_batch, y_pred))\n",
    "                valid_loss(loss)\n",
    "                valid_accuracy(y_batch, y_pred)\n",
    "            print(f\"[EPCOH: {epoch+1:3d} / {epochs:3d}, STEP: {step:6d}]: \\\n",
    "train_loss: {train_loss.result():.4f}, train_accuracy: {train_accuracy.result():.4f}, \\\n",
    "valid_loss: {valid_loss.result():.4f}, valid_accuracy: {valid_accuracy.result():.4f}\")\n",
    "        else:\n",
    "            print()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPCOH:   1 /   5, STEP:    469]: train_loss: 1.0368, train_accuracy: 0.6397, valid_loss: 0.7413, valid_accuracy: 0.7280\n",
      "[EPCOH:   2 /   5, STEP:    938]: train_loss: 0.6492, train_accuracy: 0.7603, valid_loss: 0.6315, valid_accuracy: 0.7645\n",
      "[EPCOH:   3 /   5, STEP:   1407]: train_loss: 0.5768, train_accuracy: 0.7883, valid_loss: 0.5872, valid_accuracy: 0.7841\n",
      "[EPCOH:   4 /   5, STEP:   1876]: train_loss: 0.5373, train_accuracy: 0.8043, valid_loss: 0.5575, valid_accuracy: 0.7984\n",
      "[EPCOH:   5 /   5, STEP:   2345]: train_loss: 0.5113, train_accuracy: 0.8146, valid_loss: 0.5335, valid_accuracy: 0.8068\n"
     ]
    }
   ],
   "source": [
    "kan = train_kan(kan, x_train, y_train, x_test, y_test, epochs=5, learning_rate=1e-3, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To use `update_grid_from_samples()` in Tensorflow Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2dkan_8 (Conv2DKAN)     (None, 12, 12, 8)         1658      \n",
      "                                                                 \n",
      " layer_normalization_3 (Lay  (None, 12, 12, 8)         16        \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " conv2dkan_9 (Conv2DKAN)     (None, 4, 4, 16)          24416     \n",
      "                                                                 \n",
      " global_average_pooling2d_4  (None, 16)                0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_kan_4 (DenseKAN)      (None, 10)                1290      \n",
      "                                                                 \n",
      " softmax_4 (Softmax)         (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27380 (106.95 KB)\n",
      "Trainable params: 24970 (97.54 KB)\n",
      "Non-trainable params: 2410 (9.41 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# KAN\n",
    "kan = tf.keras.models.Sequential([\n",
    "    Conv2DKAN(filters=8, kernel_size=5, strides=2, padding='valid', kan_kwargs={'grid_size': 3}),\n",
    "    tf.keras.layers.LayerNormalization(),\n",
    "    Conv2DKAN(filters=16, kernel_size=5, strides=2, padding='valid', kan_kwargs={'grid_size': 3}),\n",
    "    GlobalAveragePooling2D(),\n",
    "    DenseKAN(10, grid_size=3),\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "kan.build(input_shape=(None, 28, 28, 1))\n",
    "kan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define update grid callback\n",
    "class UpdateGridCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, training_data, batch_size: int = 128):\n",
    "        super(UpdateGridCallback, self).__init__()\n",
    "        self.training_data = tf.constant(training_data[:batch_size], tf.float32)\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        update grid before new epoch begins\n",
    "        \"\"\"\n",
    "        x_batch = self.training_data\n",
    "        if epoch > 0:\n",
    "            for layer in self.model.layers:\n",
    "                if hasattr(layer, 'update_grid_from_samples'):\n",
    "                    layer.update_grid_from_samples(x_batch)\n",
    "                x_batch = layer(x_batch)\n",
    "            print(f\"Call update_grid_from_samples at epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 55s 115ms/step - loss: 1.0145 - accuracy: 0.6429 - val_loss: 0.7153 - val_accuracy: 0.7374\n",
      "Call update_grid_from_samples at epoch 1\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 53s 113ms/step - loss: 0.6460 - accuracy: 0.7621 - val_loss: 0.6285 - val_accuracy: 0.7643\n",
      "Call update_grid_from_samples at epoch 2\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.5827 - accuracy: 0.7847 - val_loss: 0.5902 - val_accuracy: 0.7860\n",
      "Call update_grid_from_samples at epoch 3\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.5414 - accuracy: 0.8011 - val_loss: 0.5524 - val_accuracy: 0.7960\n",
      "Call update_grid_from_samples at epoch 4\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 53s 113ms/step - loss: 0.5129 - accuracy: 0.8131 - val_loss: 0.5316 - val_accuracy: 0.8047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0xffff437cc400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kan.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# add callback to training\n",
    "kan.fit(x_train, y_train, epochs=5, batch_size=128, \n",
    "        validation_data=(x_test, y_test), callbacks=[UpdateGridCallback(x_train)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
