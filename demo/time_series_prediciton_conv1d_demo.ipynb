{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tfkan.layers import Conv1DKAN\n",
    "from tfkan.layers import DenseKAN\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sine_wave(seq_length, num_samples, noise=0.1):\n",
    "    \"\"\"\n",
    "    generate a sin(t) wave time sequence with gaussian noise,\\\n",
    "    the target y is the next step of the sequence. \n",
    "    \"\"\"\n",
    "    X = np.zeros((num_samples, seq_length, 1))\n",
    "    y = np.zeros((num_samples, 1))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        start = np.random.rand() * 2 * np.pi\n",
    "        grids = np.linspace(start, start + (seq_length + 1) * 0.1, seq_length + 1)\n",
    "        X[i, :, 0] = np.sin(grids[:-1]) + noise * np.random.randn(seq_length)\n",
    "        # predict the next step\n",
    "        y[i, 0] = np.sin(grids[-1])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_sine_wave(seq_length=32, num_samples=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1dkan_20 (Conv1DKAN)    (None, 27, 3)             189       \n",
      "                                                                 \n",
      " conv1dkan_21 (Conv1DKAN)    (None, 11, 1)             307       \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 11)                0         \n",
      "                                                                 \n",
      " dense_kan_14 (DenseKAN)     (None, 1)                 188       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 684 (2.67 KB)\n",
      "Trainable params: 334 (1.30 KB)\n",
      "Non-trainable params: 350 (1.37 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Conv1DKAN(3, kernel_size=6, strides=1, kan_kwargs={\"grid_size\": 3}),\n",
    "    Conv1DKAN(1, kernel_size=6, strides=2, kan_kwargs={\"grid_size\": 3}),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    DenseKAN(1, grid_size=3)\n",
    "])\n",
    "model.build(input_shape=(None, 32, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 1s 18ms/step - loss: 0.4547 - mae: 0.5968 - val_loss: 0.4162 - val_mae: 0.5614\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3648 - mae: 0.5330 - val_loss: 0.3186 - val_mae: 0.4903\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2687 - mae: 0.4568 - val_loss: 0.2119 - val_mae: 0.3986\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.1667 - mae: 0.3577 - val_loss: 0.1143 - val_mae: 0.2892\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0812 - mae: 0.2398 - val_loss: 0.0472 - val_mae: 0.1747\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0359 - mae: 0.1543 - val_loss: 0.0241 - val_mae: 0.1243\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0221 - mae: 0.1216 - val_loss: 0.0172 - val_mae: 0.1055\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0165 - mae: 0.1041 - val_loss: 0.0139 - val_mae: 0.0954\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0135 - mae: 0.0943 - val_loss: 0.0116 - val_mae: 0.0871\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0117 - mae: 0.0875 - val_loss: 0.0099 - val_mae: 0.0812\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0102 - mae: 0.0820 - val_loss: 0.0089 - val_mae: 0.0755\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0089 - mae: 0.0765 - val_loss: 0.0077 - val_mae: 0.0714\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0079 - mae: 0.0721 - val_loss: 0.0070 - val_mae: 0.0672\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0684 - val_loss: 0.0063 - val_mae: 0.0635\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0649 - val_loss: 0.0057 - val_mae: 0.0610\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0625 - val_loss: 0.0053 - val_mae: 0.0579\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0595 - val_loss: 0.0049 - val_mae: 0.0557\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0571 - val_loss: 0.0046 - val_mae: 0.0540\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0553 - val_loss: 0.0044 - val_mae: 0.0520\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0534 - val_loss: 0.0041 - val_mae: 0.0502\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0513 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0038 - val_mae: 0.0476\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0035 - val_mae: 0.0462\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0035 - mae: 0.0472 - val_loss: 0.0034 - val_mae: 0.0448\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0033 - val_mae: 0.0443\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0032 - mae: 0.0448 - val_loss: 0.0031 - val_mae: 0.0428\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0030 - val_mae: 0.0424\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 0.0029 - val_mae: 0.0412\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0029 - mae: 0.0420 - val_loss: 0.0028 - val_mae: 0.0405\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0027 - mae: 0.0413 - val_loss: 0.0027 - val_mae: 0.0399\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0027 - mae: 0.0407 - val_loss: 0.0026 - val_mae: 0.0392\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0026 - mae: 0.0400 - val_loss: 0.0026 - val_mae: 0.0390\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0025 - mae: 0.0392 - val_loss: 0.0025 - val_mae: 0.0382\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0024 - mae: 0.0389 - val_loss: 0.0025 - val_mae: 0.0379\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0023 - mae: 0.0382 - val_loss: 0.0024 - val_mae: 0.0373\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0023 - mae: 0.0376 - val_loss: 0.0023 - val_mae: 0.0369\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0022 - mae: 0.0373 - val_loss: 0.0023 - val_mae: 0.0365\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0022 - mae: 0.0372 - val_loss: 0.0022 - val_mae: 0.0362\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0021 - mae: 0.0363 - val_loss: 0.0022 - val_mae: 0.0357\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0021 - mae: 0.0360 - val_loss: 0.0022 - val_mae: 0.0361\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0021 - mae: 0.0357 - val_loss: 0.0021 - val_mae: 0.0350\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0020 - mae: 0.0353 - val_loss: 0.0021 - val_mae: 0.0351\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0020 - mae: 0.0350 - val_loss: 0.0020 - val_mae: 0.0345\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0019 - mae: 0.0345 - val_loss: 0.0020 - val_mae: 0.0347\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0019 - mae: 0.0341 - val_loss: 0.0020 - val_mae: 0.0343\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0019 - mae: 0.0342 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0018 - mae: 0.0336 - val_loss: 0.0020 - val_mae: 0.0346\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0018 - mae: 0.0332 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0018 - mae: 0.0328 - val_loss: 0.0019 - val_mae: 0.0336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0xfffefbd48730>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
